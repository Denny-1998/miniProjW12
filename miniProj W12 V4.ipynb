{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "print(date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # load emnist Balanced dataset\n",
    "    emnist_balanced = fetch_openml('EMNIST_Balanced', as_frame=False)\n",
    "    X, y = emnist_balanced[\"data\"], emnist_balanced[\"target\"]\n",
    "    \n",
    "    X = X.reshape((-1, 28, 28))  # Reshape from flat vectors to 28x28 images\n",
    "    X = np.rot90(X, -1, axes=(1, 2))  #Rotate 90 degrees\n",
    "    X = np.fliplr(X)  #Flip images horizontally\n",
    "    \n",
    "    X = X.reshape((-1, 784))  #Reshape back to flat vectors\n",
    "    \n",
    "    y = y.astype(np.uint8)  # Convert labels to integers\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    rf_clf = RandomForestClassifier(random_state=42)\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    return rf_clf\n",
    "\n",
    "\n",
    "\n",
    "model = train_model(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 30, 60],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf_clf, param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    errors = y_test != y_pred\n",
    "    error_idx = np.where(errors)[0]\n",
    "    print(f\"Total misclassified samples: {len(error_idx)}\")\n",
    "    # Optionally visualize some of the errors\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(10, 3))\n",
    "    for ax, idx in zip(axes, error_idx[:5]):\n",
    "        image = X_test.iloc[idx].values.reshape(28, 28)\n",
    "        ax.imshow(image, cmap='gray', interpolation='nearest')\n",
    "        ax.set_title(f\"True: {y_test.iloc[idx]}, Pred: {y_pred[idx]}\")\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "error_analysis(best_model, X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
